{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48016362-7839-4670-887d-653d6b1da2fd",
   "metadata": {},
   "source": [
    "# Refine Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb69820-2522-4888-a1a7-a9a0dddaa57f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Custom Refine Chain (building steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c6529-ce4a-42f6-b367-b88988103949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain.callbacks.manager import trace_as_chain_group\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.prompt_template import format_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e7254-bbe8-4681-b8d7-92b25c5d33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain for generating initial summary based on the first document\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "first_prompt = PromptTemplate.from_template(\"Summarize this content:\\n\\n{context}\")\n",
    "document_prompt = PromptTemplate.from_template(\"{page_content}\")\n",
    "partial_format_doc = partial(format_document, prompt=document_prompt)\n",
    "summary_chain = {\"context\": partial_format_doc} | first_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db12bc-f0ba-47c7-b5f2-357b02f35742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain for refining an existing summary based on\n",
    "# an additional document\n",
    "\n",
    "refine_prompt = PromptTemplate.from_template(\n",
    "    \"Here's your first summary: {prev_response}. \"\n",
    "    \"Now add to it based on the following context: {context}\"\n",
    ")\n",
    "refine_chain = (\n",
    "    {\n",
    "        \"prev_response\": itemgetter(\"prev_response\"), \n",
    "        \"context\": lambda x: partial_format_doc(x[\"doc\"])\n",
    "    } | refine_prompt\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe1162-c9a0-42c9-ad1e-5cef42816604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final refine loop, which generates an initial summary\n",
    "# then iteratively refines it based on each of the rest of the documents\n",
    "\n",
    "def refine_loop(docs):\n",
    "    with trace_as_chain_group(\"refine loop\", inputs={\"input\": docs}) as manager:\n",
    "        summary = summary_chain.invoke(\n",
    "            docs[0], \n",
    "            config={\"callbacks\": manager, \"run_name\": \"initial summary\"}\n",
    "        )\n",
    "        for i, doc in enumerate(docs[1:]):\n",
    "            summary = refine_chain.invoke(\n",
    "                {\"prev_response\": summary, \"doc\": doc}, \n",
    "                config={\"callbacks\": manager, \"run_name\": f\"refine {i}\"}\n",
    "            )\n",
    "        manager.on_chain_end({\"output\": summary})\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dfbd8b-e0d2-4acb-b940-4e316c29d336",
   "metadata": {},
   "source": [
    "## Current approach (not using above building steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0830bcfc-bc50-467b-b1c3-0687ea21d554",
   "metadata": {},
   "source": [
    "\"query\" --> *rewrite query to search query*\n",
    "- \"Ich möchte an einem Projekt zu Augmented Reality arbeiten\" --> \"augmented reality\"\n",
    "\n",
    "- similarity search, k=4\n",
    "- get sources\n",
    "- search again with filtered sources\n",
    "- get initial and relevant chunks for each source\n",
    "- for each source: refine chain with all chunks (calls llm)\n",
    "- check generated answer for correctness (calls llm) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a053f8-8cd6-48db-b016-9ed6f681efbf",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf695bfe-b8c0-43ef-9d33-6624f08dc81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7678bb74-d2a2-4694-a75a-fd58d733b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61063f29-ee83-4732-a221-92b146d7fd33",
   "metadata": {},
   "source": [
    "**Load database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa2d9b8-4c04-423a-b147-7af9df58c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b8fb84-cd66-4f66-af8b-ae9174e427e5",
   "metadata": {},
   "source": [
    "**Get user query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0738777d-672a-46da-99a2-ddb0b46df4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"wer setzt sich mit augmented reality auseinander?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57039591-170a-4697-97f8-c4adbf450359",
   "metadata": {},
   "source": [
    "**Retrieved docs initial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5728e75-7424-4bc5-a2a6-0d783b6d1a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30de32a1580846248791c75038169b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_docs = vectordb.similarity_search(query, k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ee58a-f4f1-4d29-b94d-1bb67785a70c",
   "metadata": {},
   "source": [
    "**Get different sources**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "930aa750-d369-4502-8632-4dfbd870ecee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acke', 'webw', 'weei'}\n"
     ]
    }
   ],
   "source": [
    "sources = set()\n",
    "for doc in initial_docs:\n",
    "    sources.add(doc.metadata[\"source\"])\n",
    "\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8711e3-25fd-43da-b017-f4db239c1834",
   "metadata": {},
   "source": [
    "**For each source get all relevant chunks**\n",
    "- first chunk contains name\n",
    "- all others by semantic similarity to `query`\n",
    "</br></br>\n",
    "**ToDo**\n",
    "  - change `k` for relevant_chunks per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "489aabaf-5a45-4573-b4d3-b4dfe65be209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Load the refine QA chain\n",
    "chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"refine\", verbose=False)\n",
    "\n",
    "# Define the input documents and the question\n",
    "question = f\"Antworte auf Deutsch. Warum wurde diese Person gefunden, als der User nach dieser Frage gesucht hat: {query}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d15834-782a-474f-8abe-63c9bf9b15e0",
   "metadata": {},
   "source": [
    "### For the final step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "849dc8c4-ab17-48e9-871e-df57504b2f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "template_string = \"\"\"Stelle sicher, dass der Text grammatikalisch korrekt und kohärent ist. \\\n",
    "Falls der letzte Satz unvollständig ist, entferne ihn. Füge keine Informationen hinzu. \\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "956d3848-1019-4c5a-9537-503eb037bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56627f67-ce32-441f-ac53-300ce4c5c156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1098d2612504c058eb9e214ee258041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Philipp Ackermann wurde gefunden, weil er an der ZHAW Dozent für Informatik im Schwerpunkt \"Human-Centered Computing\" ist, was ein Teilbereich der Augmented Reality ist. Er ist auch Gründer und ehemaliger Geschäftsführer der Perspectix AG und Mitglied in verschiedenen Netzwerken wie IEEE ACM und der Schweizerischen Gesellschaft für Medizinische Informatik (SGMI). Er hat an verschiedenen Projekten gearbeitet, wie zum Beispiel Mixed Reality im Anlagenbau, epidemiologische Multiskalensimulation zur Analyse der Übertragungsmechanismen in der COVID-19-Pandemie, intelligenter Weinbau, Erstellung digitaler Gesundheitsangebote für AXA-Kunden, datengetriebenes medizinisches Muskeltraining und DeepScore: ein digitales Notenpult mit musikalischem. Er hat auch ein Papier veröffentlicht.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d20c2b068448049ef89f6b44fc22f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prof. Dr. Wibke Weber wurde gefunden, weil sie Professorin für Medienlinguistik ist und sich mit visueller Kommunikation, Augmented Reality, Virtual Reality, Medienkonvergenz, Multimodalität, Comics Journalism, Informationsdesign, Radiojournalismus und anderen Themen beschäftigt. Sie hat Forschungsarbeiten zu AR und VR veröffentlicht, wie z.B. \"Forschungsperspektiven auf AR und VR\" (Weber, 2017), \"Narrativity and beyond: visual storytelling in newsrooms\" (Weber, 2017) und \"Virtual reality as a tool for political decision-making? : an empirical study on the power of immersive images on voting behavior\" (Weber et al., 2022). Sie hat auch Forschungsarbeiten zu visuellen Stilpraktiken in Geschäftsberichten veröffentlicht, wie z.B. \"Design matters: visuelle Stilpraktiken in Geschäftsberichten\" (Weber, 2020).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f8b08aa1e84671a62ff5770fdb8dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christian Weber ist ein wissenschaftlicher Mitarbeiter am Institut für Wirtschaftsinformatik der ZHAW School of Management and Law. Er hat Forschungsprojekte, Lehre und Weiterbildung im Bereich der Augmented Reality durchgeführt, einschließlich nachhaltiger smarter Lösungen für Menschen in digitalen Ökosystemen (Digital Health, Smart & Ambient Assisted Living, Smart City, usw.), Anwendung von Mixed-Reality-Lösungen (VR/AR) in computergestützten kooperativen Arbeits- und Lernszenarien des Medizinsektors, Datenschutz, Cybersecurity, Compliance und Forensik als Enabler für digitale Ökosysteme sowie Anwendungen von Open Source Systemen im betrieblichen und infrastrukturellen Kontext von KMUs. Er hat auch Kenntnisse mit Lehrbezug (Didaktik) wie Lernen 4.0 - M.\n"
     ]
    }
   ],
   "source": [
    "# docs = []\n",
    "\n",
    "for source in sources:\n",
    "    docs = []\n",
    "        \n",
    "    # First chunk for every person containts their name and occupation\n",
    "    initial_chunk = vectordb.get(where={\"source\": source})[\"documents\"][0]\n",
    "    \n",
    "    docs.append(\n",
    "            Document(\n",
    "                page_content = initial_chunk,\n",
    "                metadata = {\"source\": source}\n",
    "            )\n",
    "    )\n",
    "    \n",
    "    # All chunks for the person related to the user query\n",
    "    docs += vectordb.similarity_search(query, k=5, filter={\"source\": source})\n",
    "\n",
    "    # Run the refine chain for all docs per person\n",
    "    result = chain({\"input_documents\": docs, \"question\": question}, return_only_outputs=True)\n",
    "\n",
    "    # Retrieve the refined answer\n",
    "    refined_answer = result[\"output_text\"]\n",
    "\n",
    "    # Make sure the answer is grammatically correct\n",
    "    refined_prompt = prompt_template.format_messages(text=refined_answer)\n",
    "    answer = chat(refined_prompt) \n",
    "\n",
    "    print(answer.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
