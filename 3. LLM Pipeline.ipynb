{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d15258-ee86-49ff-ab24-a4f81889bcbb",
   "metadata": {},
   "source": [
    "# 3. LLM Pipeline\n",
    "- based on [LangChain QA](https://python.langchain.com/docs/use_cases/question_answering/) and [LangChain RAG over in-memory documents](https://python.langchain.com/docs/use_cases/question_answering/in_memory_question_answering)\n",
    "- **make sure to place your OpenAI API key in `.env`**\n",
    "\n",
    "### ToDos\n",
    "- use LLM to generate answer to user\n",
    "- retrieve all (relevant) chunks from all retrieved sources\n",
    "    - check for each chunk whether it is relevant for the user query\n",
    "    - Chain --> let LLM summarize/decide for relevance\n",
    "    - use [refine](https://python.langchain.com/docs/modules/chains/document/refine) or [map reduce](https://python.langchain.com/docs/modules/chains/document/map_reduce)\n",
    "- rewrite user query / get additional queries for more relevant retrieval\n",
    "    - see [MultiQueryRetriever](https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f929afc-2e9d-40fb-ab8f-52d377b33507",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79607686-dc61-4a4f-8878-c6baa16b2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1490344-1772-43d2-9e2c-cbb195e0c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66374868-adee-4330-96a7-1758c11a9f71",
   "metadata": {},
   "source": [
    "### Load database from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bef1459-2c2b-4f70-a8b7-2cff4142b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40352f54-d687-497e-90f9-e48dc8565ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57834\n"
     ]
    }
   ],
   "source": [
    "# Entries in database is equivalent to number of chunks created previously\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e0b093-5615-4622-a8e6-f24c9bc0df70",
   "metadata": {},
   "source": [
    "## Query the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90c5986a-8ad4-4f6a-8bea-c51e3b8e0321",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"wer setzt sich mit augmented reality auseinander?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d742e-3d65-484a-b971-1e40de13580d",
   "metadata": {},
   "source": [
    "### Using `semantic similarity search`\n",
    "- we can specify `k` - the number of documents (here: chunks) retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53ce2db5-cb26-49a5-a0f5-9f663e71328a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a274373cf3424a34a661ed9b7130c363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_sss = vectordb.similarity_search(query, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3740fc-b3e6-4de5-8fd3-f834ca2ac701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Reality, Mixed Reality, Virtual Reality, Information Visualization, Digital Health, Mobile Apps, Audio & Music Processing. Aus- und Fortbildung Dr. oec. publ. UniZHResearch Assistant at Multimedia Lab / Institut für Informatik / Universität Zürich Beruflicher Werdegang Gründer und ehem. Geschäftsführer der Perspectix AG Mitglied in Netzwerken IEEE ACM Schweizerische Gesellschaft für Medizinische Informatik (SGMI) Projekte Mixed Reality im Anlagenbau / ProjektleiterIn / Projekt laufend\n"
     ]
    }
   ],
   "source": [
    "# Example of first result retrieved\n",
    "print(results_sss[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e35ba1e-b0ff-45df-a86b-622b4932510b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acke\n"
     ]
    }
   ],
   "source": [
    "print(results_sss[0].metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e7c786-fe29-4959-8080-d7d5dd07f6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{'weei', 'acke', 'webw'}\n"
     ]
    }
   ],
   "source": [
    "# Number of different sources retrieved\n",
    "sources = set()\n",
    "for result in results_sss:\n",
    "    sources.add(result.metadata[\"source\"])\n",
    "\n",
    "print(len(sources))\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce26bc7b-ac4c-4f19-b4a9-0ccceb17f934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_sss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c47488-b515-470b-a8ef-dd26b639d348",
   "metadata": {},
   "source": [
    "### Using `maximum marginal relevance`\n",
    "- strives to achieve both relevance to the query and diversity among the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13200f3b-1c2f-4c5f-b9e3-5858e8a14347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b926e5bd354c3b9e0c19b4aa04e69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_mmr = vectordb.max_marginal_relevance_search(query, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79c4e6dc-aa46-4752-b62b-f4129dc0a049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "{'shmt', 'mede', 'acke', 'pach'}\n"
     ]
    }
   ],
   "source": [
    "# Number of different sources retrieved\n",
    "sources_mmr = set()\n",
    "for result in results_mmr:\n",
    "    sources_mmr.add(result.metadata[\"source\"])\n",
    "\n",
    "print(len(sources_mmr))\n",
    "print(sources_mmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1e35739-ad66-458e-93de-8e6b594b5d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='von Windenergieanlagen mit Augmented Reality / Teammitglied / Projekt abgeschlossen Wasserregime Sur Chaunt Blais, St. Moritz / Teammitglied / Projekt abgeschlossen Beschneiung Minschuns - Umweltverträglichkeitsbericht (UVB) / Teammitglied / Projekt abgeschlossen Umweltverträglichkeitsbericht (UVB) Umfahrungsstrasse Sta. Maria, Kt. GR / Teammitglied / Projekt abgeschlossen Publikationen Beiträge in wissenschaftlicher Zeitschrift, peer-reviewed Bergauer, Miro; Dembicz, Iwona; Boch, Steffen;', metadata={'source': 'pach'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mmr[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f84367-7ccc-43a0-ad33-87472b3d626a",
   "metadata": {},
   "source": [
    "## Approach 1: Building the context for our LLM prompt based on chunks\n",
    "- we can retrieve all chunks for a retrieved source (`\"shorthandSymbol\"`) and use these as inputs to `refine` our context / prompt\n",
    "- **TBD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "153936ae-7bf9-456a-8ff8-f52312429257",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_query = vectordb.get(where={\"source\": results_mmr[3].metadata[\"source\"]})\n",
    "all_chunks_from_single_source = complete_query[\"documents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0107f129-4b05-4d33-8ccf-0ffd1303e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complete_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "489585fe-bd63-49fc-b27f-418b93d8c965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Martin Schuler Martin Schuler ZHAW Angewandte Linguistik Institut für Übersetzen und Dolmetschen Theaterstrasse 15c 8400 Winterthur +41 (0) 58 934 62 21 martin.schuler@zhaw.ch Persönliches Profil Leitungsfunktion Leitung Usability-Labor Tätigkeit an der ZHAW Wiss. Mitarbeiter im Forschungs- und Arbeitsbereich Technikkommunikationaktuelle Lehrtätigkeit an der ZHAWVorlesungen- Usability mit Schwerpunkt Web-Usability- LokalisierungSeminare- Usability-Testing- Projekt in der Technischen\n"
     ]
    }
   ],
   "source": [
    "print(len(all_chunks_from_single_source))\n",
    "print(all_chunks_from_single_source[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fbad71b4-c099-4049-b5fb-f0e34f125cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cfd1fe78-d595-4bd1-81d0-22e539ba9907",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_list = []\n",
    "i= 0\n",
    "for chunk in all_chunks_from_single_source:\n",
    "    metadata = {\"source\": i}\n",
    "    chunk_list.append(Document(page_content=chunk, metadata=metadata))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491e311-887b-4396-b181-485bb059b5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Load the refine QA chain\n",
    "chain = load_qa_with_sources_chain(OpenAI(), chain_type=\"refine\", verbose=True)\n",
    "\n",
    "# Define the input documents and the question\n",
    "docs = chunk_list\n",
    "question = f\"antworte auf deutsch. deine antwort soll nur das enthalten, was zur beantwortung der frage beiträgt. wenn nichts dazu beiträgt, dann lasse deine antwort einfach leer. die frage lautet: warum wurde diese person gefunden mit dieser suchanfrage: {query}\"\n",
    "\n",
    "# Run the refine QA chain\n",
    "result = chain({\"input_documents\": docs, \"question\": question}, return_only_outputs=True)\n",
    "\n",
    "# Retrieve the output answer\n",
    "answer = result[\"output_text\"]\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2292af-e486-412b-9afc-c834f4a5d640",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Use our database as a retriever for LangChain\n",
    "- see [Agent with retrieval tool](https://python.langchain.com/docs/use_cases/question_answering/conversational_retrieval_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe6bc85-8c46-45e7-affd-91c105fe2b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f03a4aa-68f7-49c9-ba0d-da9a927648ba",
   "metadata": {},
   "source": [
    "**Retriever tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f45d7-f0e0-4662-bbf7-d0b418142de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9811f2-6662-4c33-b6ec-29a9fedc2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = create_retriever_tool(\n",
    "    retriever, \n",
    "    \"search_zhaw_employees\",\n",
    "    \"Searches the user profiles of the ZHAW employees.\"\n",
    ")\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3bf9db-6a8a-4e2f-82fc-925e7e6a697c",
   "metadata": {},
   "source": [
    "result[\"output\"]**Agent constructor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e4c39d-ec2a-4392-a7c5-5a21d0a33e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f055ba9-da4a-4efc-861e-a49235ff244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575de95a-5b31-4226-91d0-861c151e1def",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_conversational_retrieval_agent(llm, tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256dfeab-d532-4749-a7c2-ea90004a6320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor({\"input\": \"hi, im bob\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"output\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent_executor({\"input\": \"whats my name?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent_executor({\"input\": \"is there someone at ZHAW who works on augmented reality?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent_executor({\"input\": \"can you tell me more about the people working on augmented reality at ZHAW?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
